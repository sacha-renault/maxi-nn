# type: ignore
import sys
from typing import Literal, List, Any, Optional, Tuple, Dict
import numpy as np
import enum
import numpy

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  AUTOGENERATED CODE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# <litgen_stub> // Autogenerated code below! Do not edit!
####################    <generated_from:Tensor.hpp>    ####################

class TensorType(enum.Enum):
    input = enum.auto()     # (= 0)
    output = enum.auto()    # (= 1)
    parameter = enum.auto() # (= 2)
    none = enum.auto()      # (= 3)

#  ------------------------------------------------------------------------
#      <template specializations for class Tensor>
class Tensor_float:  # Python specialization for Tensor<float>
    # static factory method
    @staticmethod
    @overload
    def create() -> Tensor<T>:
        pass
    @staticmethod
    @overload
    def create(dim: xt.dynamic_shape<int>, requires_grad: bool = True) -> Tensor<T>:
        pass
    @staticmethod
    @overload
    def create(values: xt.xarray<float>, requires_grad: bool = True) -> Tensor<T>:
        pass
    @staticmethod
    @overload
    def create(
        values: xt.xarray<float>,
        stream: Operation.IOperation<float>,
        requires_grad: bool = True
        ) -> Tensor<T>:
        pass
    @staticmethod
    def zeros(dim, requires_grad: bool = True) -> Tensor<T>:
        pass
    @staticmethod
    def ones(dim, requires_grad: bool = True) -> Tensor<T>:
        pass
    @staticmethod
    def random(
        dim: xt.dynamic_shape<int>,
        min: float = 0,
        max: float = 1,
        requires_grad: bool = True
        ) -> Tensor<T>:
        pass
    @staticmethod
    def normal(
        dim: xt.dynamic_shape<int>,
        mean: float = 0,
        stddev: float = 1,
        requires_grad: bool = True
        ) -> Tensor<T>:
        pass

    def set_tensor_type(self, type: TensorType) -> None:
        """ set a type for the tensor"""
        pass

    # gradient
    def accumulate_grad(self, add_grad: xt.xarray<float>) -> None:
        pass
    def set_grad(self, grads: xt.xarray<float>) -> None:
        pass
    def get_grad(self) -> xt.xarray<float>:
        pass
    def reset_grad(self) -> None:
        pass
    def set_ones_grad(self) -> None:
        pass
    def add_child(self, child: Tensor<T>) -> None:
        pass
    def get_children(self) -> std.vector<Tensor<T>>:
        pass

    # graph computations
    def backward(self) -> None:
        pass
    def forward(self) -> None:
        pass

    # values
    def set_values(self, new_values: xt.xarray<float>) -> None:
        pass
    def get_values(self) -> np.ndarray:
        pass
    @overload
    def fill(self, value: float) -> None:
        pass
    @overload
    def fill(self, values: xt.xarray<float>) -> None:
        pass
    def __getitem__(self, idx: xt.xindex) -> float:
        pass
    def get_item(self, idx: xt.xindex) -> float:
        pass
    def slice(self, slices: xt.xstrided_slice_vector) -> Tensor<T>:
        pass

    # size etc...
    def size(self) -> int:
        pass
    def shape(self) -> xt.dynamic_shape<int>:
        pass
    # None reshape(xt::dynamic_shape<size_t> dim);

    # for user
    def display(self) -> None:
        pass
    def display_grad(self) -> None:
        pass
#      </template specializations for class Tensor>
#  ------------------------------------------------------------------------


####################    </generated_from:Tensor.hpp>    ####################

# </litgen_stub> // Autogenerated code end!